geom_bar(stat = "identity")
ggplot(df, aes(x = name, y = a, fill = name)) +
scale_fill_tq(alpha = 0.5) +
geom_bar(stat = "identity", alpha = 0.5)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq(alpha = 0.5) +
geom_bar(stat = "identity", alpha = 0.5)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.5)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
df <- data.frame(a = 1:20, name = 1:20)
df$name <- factor(df$name)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
df <- data.frame(a = 1:12, name = 1:12)
df$name <- factor(df$name)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 1)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.7)
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
theme_classic() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.7)
?scale_fill_tq
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
theme_classic() +
scale_fill_tq(theme = "dark") +
geom_bar(stat = "identity", alpha = 0.7)
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
theme_classic() +
scale_fill_tq(theme = "light") +
geom_bar(stat = "identity", alpha = 0.7)
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
theme_classic() +
scale_fill_tq(theme = "green") +
geom_bar(stat = "identity", alpha = 0.7)
?scale_fill_binned
theme_tq
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
#theme_classic() +
theme_tq() +
scale_fill_tq(theme = "green") +
geom_bar(stat = "identity", alpha = 0.7)
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
#theme_classic() +
theme_tq() +
#scale_fill_tq(theme = "green") +
geom_bar(stat = "identity")
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
#theme_classic() +
theme_tq() +
scale_fill_tq() +
geom_bar(stat = "identity")
theme_tq
ggplot(df, aes(x = name, y = a, fill = name)) +
#theme_light() +
#theme_classic() +
theme_tq_dark() +
scale_fill_tq() +
geom_bar(stat = "identity")
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity")
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_light() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_classic() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_classic() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.5)
ggplot(df, aes(x = name, y = a, fill = name)) +
theme_classic() +
scale_fill_tq() +
geom_bar(stat = "identity", alpha = 0.8)
remove(list = ls())
library(tidyverse)
library(curatedMetagenomicData)
library(vegan)
#load("~/Downloads/sampleMetadata.rda")
dim(sampleMetadata)
remove(list = ls())
library(tidyverse)
library(curatedMetagenomicData)
library(vegan)
load("~/Downloads/sampleMetadata.rda")
d <- sampleMetadata %>% returnSamples("relative_abundance")
install.packages("curatedMetagenomicData")
library(curatedMetagenomicData)
d <- sampleMetadata %>% returnSamples("relative_abundance")
curatedMetagenomicData()
BiocManager::install("curatedMetagenomicData")
library(curatedMetagenomicData)
d <- sampleMetadata %>% returnSamples("relative_abundance")
library(curatedMetagenomicData)
library(tidyverse)
library(curatedMetagenomicData)
d <- sampleMetadata %>% returnSamples("relative_abundance")
returnSamples
library(curatedMetagenomicData)
returnSamples
?curatedMetagenomicData
package_version(curatedMetagenomicData)
package_version("curatedMetagenomicData")
package.version("curatedMetagenomicData")
BiocManager::install("waldronlab/curatedMetagenomicData", dependencies = TRUE, build_vignettes = TRUE)
BiocManager::install("curatedMetagenomicData")
d <- readRDS("~/Downloads/Gut-microbiome-immunotherapy-master/Metadata/Processed_metadata/clin.rds")
head(d)
dim(d)
library(mlr3)
library(mlr3proba)
library(survival)
library(mlr3viz)
library(devtools)
library(GGally)
#survival::bladder2[, -1L]
#as_task_surv(survival::bladder2[, -1L], id = "interval_censored", time = "start", event = "event", time2 = "stop", type = "interval")
# type = "right" is default
survival::rats
task = as_task_surv(survival::rats, id = "right_censored", time = "time", event = "status", type = "right")
print(task)
autoplot(task)
task = tsk("rats")
learn = lrn("surv.coxph")
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)
learn$train(task, row_ids = train_set)
prediction = learn$predict(task, row_ids = test_set)
print(prediction)
##
library("mlr3pipelines")
library("mlr3learners")
library(Rcpp)
# PipeOpDistrCompositor - Train one model with a baseline distribution,
# (Kaplan-Meier or Nelson-Aalen), and another with a predicted linear predictor.
task = tsk("rats")
# remove the factor column for support with glmnet
task$select(c("litter", "rx"))
learner_lp = lrn("surv.glmnet")
learner_distr = lrn("surv.kaplan")
prediction_lp = learner_lp$train(task)$predict(task)
prediction_distr = learner_distr$train(task)$predict(task)
prediction_lp
prediction_lp$distr
# Doesn't need training. Base = baseline distribution. ph = Proportional hazards.
pod = po("compose_distr", form = "ph", overwrite = FALSE)
prediction = pod$predict(list(base = prediction_distr, pred = prediction_lp))$output
prediction
# Now we have a predicted distr!
##prediction$distr
# This can all be simplified by using the distrcompose pipeline
glm.distr = ppl("distrcompositor", learner = lrn("surv.glmnet"),
estimator = "kaplan", form = "ph", overwrite = FALSE, graph_learner = TRUE)
glm.distr$train(task)$predict(task)
library("mlr3learners")
task = tsk("rats")
# some integrated learners
learners = lrns(c("surv.coxph", "surv.kaplan", "surv.ranger"))
print(learners)
# Harrell's C-Index for survival
measure = msr("surv.cindex")
print(measure)
set.seed(1)
bmr = benchmark(benchmark_grid(task, learners, rsmp("cv", folds = 3)))
bmr$aggregate(measure)
autoplot(bmr, measure = measure)
bmr
str(bmr)
bmr$aggregate(measure)
bmr$aggregate()
bmr$aggregate
bmr$aggregate()
# Harrell's C-Index for survival
measure = msr("surv.cindex")
print(measure)
measure
measure$aggregate()
str(measure)
measure$print()
measure$average
mode(measure)
measure
library(mlr3pipelines); library(mlr3); library(mlr3tuning); library(paradox)
install.packages("mlr3tuning")
library(mlr3pipelines); library(mlr3); library(mlr3tuning); library(paradox)
set.seed(42)
task = tgen("simsurv")$generate(50)
library(simsurv)
install.packages("simsurv")
library(simsurv)
set.seed(42)
task = tgen("simsurv")$generate(50)
composed_lrn_gbm = distrcompositor(lrn("surv.gbm", bag.fraction = 1, n.trees = 50L),
"kaplan", "ph")
#composed_lrn_gbm = distrcompositor(lrn("surv.gbm", bag.fraction = 1, n.trees = 50L),
composed_lrn_gbm = distrcompositor(lrn("surv.xgboost", bag.fraction = 1, n.trees = 50L),
"kaplan", "ph")
#composed_lrn_gbm = distrcompositor(lrn("surv.gbm", bag.fraction = 1, n.trees = 50L),
composed_lrn_gbm = distrcompositor(lrn("surv.glmnet", bag.fraction = 1, n.trees = 50L),
"kaplan", "ph")
data(lung, package = "survival")
lung$status = (lung$status == 2) # convert to logical
surv.task = makeSurvTask(data = lung, target = c("time", "status"))
library(mlr)
library(tidyverse)
library(vegan)
library(reshape2)
library(glm2)
library(clusterSim)
library(microbiome)
library(DirichletMultinomial)
## enterotype ########################################################################################
#dist.JSD <- function(inMatrix, pseudocount = 0.0001, ...) {
dist.JSD <- function(inMatrix, pseudocount, ...) {
KLD <- function(x,y) sum(x *log(x/y))
JSD<- function(x,y) sqrt(0.5 * KLD(x, (x+y)/2) + 0.5 * KLD(y, (x+y)/2))
matrixColSize <- length(colnames(inMatrix))
matrixRowSize <- length(rownames(inMatrix))
colnames <- colnames(inMatrix)
resultsMatrix <- matrix(0, matrixColSize, matrixColSize)
inMatrix = apply(inMatrix,1:2,function(x) ifelse (x==0,pseudocount,x))
for(i in 1:matrixColSize) {
for(j in 1:matrixColSize) {
resultsMatrix[i,j]=JSD(as.vector(inMatrix[,i]),
as.vector(inMatrix[,j]))
}
}
colnames -> colnames(resultsMatrix) -> rownames(resultsMatrix)
as.dist(resultsMatrix)->resultsMatrix
attr(resultsMatrix, "method") <- "dist"
return(resultsMatrix)
}
plot_value <- function(fit){
lplc <- sapply(fit, laplace) # AIC / BIC / Laplace
aic  <- sapply(fit, AIC) # AIC / BIC / Laplace
bic  <- sapply(fit, BIC) # AIC / BIC / Laplace
temp1 <- data.frame(cluster = 1:5, value = lplc, index = "laplace" )
temp2 <- data.frame(cluster = 1:5, value = aic, index = "aic" )
temp3 <- data.frame(cluster = 1:5, value = bic, index = "bic" )
df <- rbind(temp1, temp2, temp3)
p <- ggplot(df, aes(x = cluster, y = value, col = index)) +
theme_bw() +
geom_point() +
geom_line(aes(group = index))
return(p)
}
## JP genus
d <- read_rds("~/Desktop/motusMatrix_gtdbGenuslevel_adults.rds") %>% t()
## filtering samples with low reads
keep <- apply(d, 1, sum) > 1E3
d <- d[keep, ]
## transform to prop
d <- prop.table(as.matrix(d), margin = 1)
## filtering minor species
apply(d, 2, mean) %>% head()
keep <- apply(d, 2, mean) > 1E-4 & apply(d > 0, 2, mean) > 0.1
d <- d[, keep]
## transform to count
d <- round(d * 1E3)
sample(1:nrow(d), nrow(d)/100)
sample(1:nrow(d), nrow(d)/20)
sample(1:nrow(d), nrow(d)/50)
sample(1:nrow(d), nrow(d)/30)
rand <- sample(1:nrow(d), nrow(d)/30)
d <- d[rand, ]
dim(d)
## JP genus
d <- read_rds("~/Desktop/motusMatrix_gtdbGenuslevel_adults.rds") %>% t()
## filtering samples with low reads
keep <- apply(d, 1, sum) > 1E3
d <- d[keep, ]
## transform to prop
d <- prop.table(as.matrix(d), margin = 1)
## filtering minor species
apply(d, 2, mean) %>% head()
keep <- apply(d, 2, mean) > 1E-4 & apply(d > 0, 2, mean) > 0.1
d <- d[, keep]
## transform to count
d <- round(d * 1E3)
rand <- sample(1:nrow(d), nrow(d)/20)
d <- d[rand, ]
dim(d)
fit <- lapply(1:5, dmn, count = as.matrix(d), verbose=TRUE)
#saveRDS(fit, file = "enterotype.R.out/fit.JP_4D.genus.rds")
plot_value(fit)
#saveRDS(fit, file = "enterotype.R.out/fit.JP_4D.genus.rds")
p <- plot_value(fit)
ggsave(p, filename = "~/Desktop/plot.pdf", width = 4, height = 4)
ggsave(p, filename = "~/Desktop/plot.pdf", width = 4, height = 3)
library("mlr3")
task = tsk("iris")
learner = lrn("classif.rpart")
# train a model of this learner for a subset of the task
learner$train(task, row_ids = 1:120)
# this is what the decision tree looks like
learner$model
predictions = learner$predict(task, row_ids = 121:150)
predictions
predictions$score(msr("classif.acc"))
library("mlr3")
library("mlr3proba")
library("survival")
as_task_surv(survival::bladder2[, -1L], id = "interval_censored",
time = "start", event = "event", time2 = "stop", type = "interval")
# type = "right" is default
task = as_task_surv(survival::rats, id = "right_censored", time = "time", event = "status", type = "right")
print(task)
library("mlr3viz")
autoplot(task)
task = tsk("rats")
learn = lrn("surv.coxph")
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)
learn$train(task, row_ids = train_set)
prediction = learn$predict(task, row_ids = test_set)
print(prediction)
library("mlr3pipelines")
library("mlr3learners")
# PipeOpDistrCompositor - Train one model with a baseline distribution,
# (Kaplan-Meier or Nelson-Aalen), and another with a predicted linear predictor.
task = tsk("rats")
# remove the factor column for support with glmnet
task$select(c("litter", "rx"))
learner_lp = lrn("surv.glmnet")
learner_distr = lrn("surv.kaplan")
prediction_lp = learner_lp$train(task)$predict(task)
prediction_distr = learner_distr$train(task)$predict(task)
prediction_lp$distr
pod = po("compose_distr", form = "ph", overwrite = FALSE)
prediction = pod$predict(list(base = prediction_distr, pred = prediction_lp))$output
prediction$distr
glm.distr = ppl("distrcompositor", learner = lrn("surv.glmnet"),
estimator = "kaplan", form = "ph", overwrite = FALSE, graph_learner = TRUE)
glm.distr$train(task)$predict(task)
library("mlr3")
library("mlr3proba")
library("survival")
as_task_surv(survival::bladder2[, -1L], id = "interval_censored",
time = "start", event = "event", time2 = "stop", type = "interval")
# type = "right" is default
task = as_task_surv(survival::rats, id = "right_censored", time = "time", event = "status", type = "right")
print(task)
library("mlr3viz")
autoplot(task)
task = tsk("rats")
learn = lrn("surv.coxph")
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)
learn$train(task, row_ids = train_set)
prediction = learn$predict(task, row_ids = test_set)
print(prediction)
library("mlr3pipelines")
library("mlr3learners")
# PipeOpDistrCompositor - Train one model with a baseline distribution,
# (Kaplan-Meier or Nelson-Aalen), and another with a predicted linear predictor.
task = tsk("rats")
# remove the factor column for support with glmnet
task$select(c("litter", "rx"))
learner_lp = lrn("surv.glmnet")
learner_distr = lrn("surv.kaplan")
prediction_lp = learner_lp$train(task)$predict(task)
prediction_distr = learner_distr$train(task)$predict(task)
prediction_lp$distr
# Doesn't need training. Base = baseline distribution. ph = Proportional hazards.
pod = po("compose_distr", form = "ph", overwrite = FALSE)
prediction = pod$predict(list(base = prediction_distr, pred = prediction_lp))$output
# Now we have a predicted distr!
prediction$distr
# This can all be simplified by using the distrcompose pipeline
glm.distr = ppl("distrcompositor", learner = lrn("surv.glmnet"),
estimator = "kaplan", form = "ph", overwrite = FALSE, graph_learner = TRUE)
glm.distr$train(task)$predict(task)
library("mlr3learners")
task = tsk("rats")
# some integrated learners
learners = lrns(c("surv.coxph", "surv.kaplan", "surv.ranger"))
print(learners)
# Harrell's C-Index for survival
measure = msr("surv.cindex")
print(measure)
set.seed(1)
bmr = benchmark(benchmark_grid(task, learners, rsmp("cv", folds = 3)))
bmr$aggregate(measure)
autoplot(bmr, measure = measure)
# some integrated learners
learners = lrns(c("surv.coxph", "surv.kaplan", "surv.ranger", "surv.xgboost"))
print(learners)
# Harrell's C-Index for survival
measure = msr("surv.cindex")
print(measure)
set.seed(1)
bmr = benchmark(benchmark_grid(task, learners, rsmp("cv", folds = 3)))
bmr$aggregate(measure)
autoplot(bmr, measure = measure)
d <- read.delim("~/OP239GALAHPMainProje-Kostsprgeskemaer_DATA_2022-04-08_1254.csv", sep = "|", header = T, row.names = 1)
d <- read.delim("~/ownCloud/GALAXY/dietary_data/OP239GALAHPMainProje-Kostsprgeskemaer_DATA_2022-04-08_1254.csv", sep = "|", header = T, row.names = 1)
dim(d)
apply(is.na(d), 2, sum)
apply(is.na(d), 1, sum)
rownames(d)
apply(is.na(d), 1, sum) %>% data.frame()
library(tidyverse)
apply(is.na(d), 1, sum) %>% data.frame()
d <- read.delim("~/Desktop/sample_export_rich.tsv")
colnames(d) %>% data.frame()
d$tissue_type %>% table()
d$age_years<3
table(d$environment_feature)
table(d$subject_disease_status) %>% data.frame() %>% arrange(Freq)
library(tidyverse)
d <- d %>%
filter(age_years > 3) %>%
filter(tissue_type == "" | tissue_type == "Stool") %>%
filter(environment_feature == "intestine environment [ENVO:2100002]" | environment_feature == "feces [ENVO:00002003]")
table(d$subject_disease_status) %>% data.frame() %>% arrange(Freq)
Cstack_info()
Cstack_info()
Cstack_info()
Cstack_info()
170/120
650009*12
library(MLP)
# read input file (mOTUs v2.5)
input <- read.delim("~/Downloads/test_data/test_data/Franzosa_2018_IBD.motus25.tsv", header = T, row.names = 1, check.names = F)
# transpose the data
input <- data.frame(t(input), check.names = F)
# predict microbial loads
load <- MLP(input, "motus25", "load")
MLP()
MLP
# predict microbial loads
load <- MLP(input, "metacardis", "motus25", "load")
# predict microbial loads
load <- MLP(input, "motus25", "metacardis", "load")
setwd("~/microbial_load_predictor/")
# predict microbial loads
load <- MLP(input, "motus25", "metacardis", "load")
library(MLP)
# read input file (mOTUs v2.5)
input <- read.delim("~/Downloads/test_data/test_data/Franzosa_2018_IBD.motus25.tsv", header = T, row.names = 1, check.names = F)
# transpose the data
input <- data.frame(t(input), check.names = F)
# predict microbial loads
load <- MLP(input, "motus25", "metacardis", "load")
library(tidyverse)
# predict microbial loads
load <- MLP(input, "motus25", "metacardis", "load")
load %>% head()
rownames(load) %>% head()
load %>% rownames_to_column(sample_id = .) %>% head()
load %>% rownames_to_column(`sample ID` = .) %>% head()
load %>% rownames_to_column(var = `sample ID`) %>% head()
load %>% rownames_to_column(var = "sample ID") %>% head()
qmp <- MLP(input, "motus25", "metacardis", "qmp")
qmp[1:5, 1:5]
write.table(qmp[1:5, 1:5], file = "~/Desktop/temp.tsv", sep = "\t", col.names = NA)
load %>% rownames_to_column(var = "sample ID") %>% head()
load <- load %>% rownames_to_column(var = "sample ID") %>% head()
write.table(load, file = "~/Desktop/temp.load.tsv", sep = "\t", col.names = NA)
write.table(load, file = "~/Desktop/temp.load.tsv", sep = "\t")
qmp <- MLP(input, "motus25", "metacardis", "qmp")
qmp <- qmp %>% rownames_to_column(var = "")
#write.table(qmp[1:5, 1:5], file = "~/Desktop/temp.tsv", sep = "\t", col.names = NA)
write_tsv(qmp[1:5, 1:5], file = "~/Desktop/temp.qmp.tsv")
qmp <- MLP(input, "motus25", "metacardis", "qmp")
qmp[1:5, 1:5]
qmp <- qmp %>% rownames_to_column(var = "")
qmp[1:5, 1:5]
qmp <- MLP(input, "motus25", "metacardis", "qmp")
rownames(qmp) %>% head()
qmp[1:5, 1:5]
qmp <- qmp %>% rownames_to_column(var = "")
qmp <- qmp %>% rownames_to_column(var = "species")
qmp[1:5, 1:5]
qmp <- qmp %>% rownames_to_column(var = "sample ID")
qmp[1:5, 1:5]
qmp <- MLP(input, "motus25", "metacardis", "qmp")
qmp[1:5, 1:5]
qmp <- qmp %>% rownames_to_column(var = "sample ID")
qmp[1:5, 1:5]
#write.table(qmp[1:5, 1:5], file = "~/Desktop/temp.tsv", sep = "\t", col.names = NA)
write_tsv(qmp[1:5, 1:5], file = "~/Desktop/temp.qmp.tsv")
